{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成叶片前景区域（MOCO之后操作）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def kd_fill_holes(image_path):\n",
    "    # 读取图像\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # 二值化\n",
    "    ret, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # 填充孔洞\n",
    "    filled_image = cv2.bitwise_not(cv2.bitwise_not(binary_image.copy()))\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    filled_image = cv2.bitwise_not(cv2.bitwise_not(cv2.morphologyEx(filled_image, cv2.MORPH_CLOSE, kernel)))\n",
    "    return filled_image\n",
    "\n",
    "def segment_foreground(original_image, mask_image):\n",
    "    # 将掩码图转换为二值图像\n",
    "    _, binary_mask = cv2.threshold(mask_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    # 使用掩码图过滤原始图像\n",
    "    foreground = cv2.bitwise_and(original_image, original_image, mask=binary_mask)\n",
    "    return foreground\n",
    "\n",
    "# 原图文件夹和掩码图文件夹路径\n",
    "original_images_folder = \"./experiments/data/Publish_Dataset/Pixel-level_annotation/Image/\"\n",
    "mask_images_folder = \"./experiments/predictions/CCAM_Apple_MOCO@scale=0.5,1.0,1.5,2.0@t=0.5@ccam_inference_crf=10/\"\n",
    "\n",
    "# 遍历原图文件夹\n",
    "for filename in os.listdir(original_images_folder):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        original_image_path = os.path.join(original_images_folder, filename)\n",
    "        \n",
    "        # 加载原始图像\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "\n",
    "        # 构建对应的掩码图像路径\n",
    "        mask_image_path = os.path.join(mask_images_folder, filename.split('.')[0] + '.png')\n",
    "        \n",
    "        # 如果对应的掩码图像存在，则进行处理\n",
    "        if os.path.exists(mask_image_path):\n",
    "            original_image = cv2.resize(original_image, (512, 512))\n",
    "\n",
    "            # mask_image = cv2.imread(mask_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask_image = kd_fill_holes(mask_image_path)\n",
    "\n",
    "            # 分割前景部分\n",
    "            foreground = segment_foreground(original_image, mask_image)\n",
    "            \n",
    "            # 保存分割后的前景部分为 PNG 格式，其中背景区域被设置为透明\n",
    "            transparent_png = np.zeros((foreground.shape[0], foreground.shape[1], 4), dtype=np.uint8)\n",
    "            transparent_png[:, :, :3] = foreground  # 将前景部分复制到新图像的 RGB 通道\n",
    "            transparent_png[:, :, 3] = (mask_image != 0) * 255  # 使用掩码图的非零像素值作为透明度通道的值\n",
    "\n",
    "            output_path = os.path.join(\"./experiments/predictions/Leaf_Foreground/\", filename.split('.')[0] + '.png')\n",
    "            cv2.imwrite(output_path, transparent_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显著性目标检测评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 IoU,准确率,精确率,召回率,F1 分数,MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# 定义转换函数，将图像加载并转换为 PyTorch 张量\n",
    "def load_and_transform_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')  # 以灰度模式打开图像\n",
    "    image = ToTensor()(image)  # 转换为 PyTorch 张量\n",
    "    return image\n",
    "\n",
    "def is_image_file(filename):\n",
    "    # if filename.startswith(\"Strawberry\"):\n",
    "    #     return False\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
    "\n",
    "def read_file_names_from_txt(txt_file):\n",
    "    with open(txt_file, 'r') as f:\n",
    "        return set(line.strip() for line in f)\n",
    "    \n",
    "def evaluating(pred_folder, gt_folder,file_path):\n",
    "    # 初始化指标\n",
    "    iou_total = 0.0\n",
    "    dice_total = 0.0\n",
    "    accuracy_total = 0.0\n",
    "    precision_total = 0.0\n",
    "    recall_total = 0.0\n",
    "    f1_total = 0.0\n",
    "    mae_total = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 遍历 GT 图像文件\n",
    "    for root, _, gt_files in os.walk(pred_folder):\n",
    "        for gt_file in gt_files:\n",
    "            if is_image_file(gt_file):\n",
    "                # 构建 GT 图像文件和预测显著图像文件的完整路径\n",
    "                gt_path = os.path.join(gt_folder, gt_file)\n",
    "                pred_path = os.path.join(pred_folder, gt_file)  # 假设预测图像在一个文件夹中\n",
    "\n",
    "                if not os.path.exists(pred_path):\n",
    "                    continue  # 如果预测图像不存在，跳过该文件\n",
    "\n",
    "                # 加载 GT 图像和预测显著图像\n",
    "                gt_image = load_and_transform_image(gt_path)\n",
    "                pred_image = load_and_transform_image(pred_path)\n",
    "\n",
    "                # 检查大小是否匹配\n",
    "                if gt_image.size() != pred_image.size():\n",
    "                    print(f\"Size mismatch for {gt_file}: GT {gt_image.size()} vs Pred {pred_image.size()}\")\n",
    "                    continue\n",
    "\n",
    "                # 计算二值化的 GT 图像和预测显著图像\n",
    "                gt_binary = (gt_image > 0.5).float()  # 二值化，可以根据阈值调整\n",
    "                pred_binary = (pred_image > 0.5).float()  # 二值化，可以根据阈值调整\n",
    "\n",
    "                # 计算 IoU\n",
    "                intersection = torch.sum(gt_image * pred_binary)\n",
    "                union = torch.sum((gt_image + pred_binary) > 0)\n",
    "                iou = intersection / union\n",
    "                iou_total += iou.item()\n",
    "\n",
    "                # 计算 Dice\n",
    "                dice = (2.0 * intersection ) / (torch.sum(pred_binary) + torch.sum(gt_image) )\n",
    "                dice_total += dice.item()\n",
    "                \n",
    "                # 计算准确率\n",
    "                accuracy = torch.sum((gt_binary == pred_binary).float()) / gt_binary.numel()\n",
    "                accuracy_total += accuracy.item()\n",
    "\n",
    "                # 计算精确率、召回率和 F1 分数\n",
    "                true_positive = torch.sum(gt_binary * pred_binary)\n",
    "                false_positive = torch.sum((1 - gt_binary) * pred_binary)\n",
    "                false_negative = torch.sum(gt_binary * (1 - pred_binary))\n",
    "\n",
    "                precision = true_positive / (true_positive + false_positive + 1e-8)\n",
    "                recall = true_positive / (true_positive + false_negative + 1e-8)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "                precision_total += precision.item()\n",
    "                recall_total += recall.item()\n",
    "                f1_total += f1.item()\n",
    "\n",
    "                # 计算 MAE\n",
    "                abs_error = torch.abs(pred_image - gt_image)\n",
    "                mae = torch.mean(abs_error)\n",
    "                mae_total += mae.item()\n",
    "\n",
    "                total_samples += 1\n",
    "\n",
    "    if total_samples == 0:\n",
    "        print(\"No valid samples found.\")\n",
    "        return\n",
    "    # 计算平均指标值\n",
    "    average_iou = iou_total / total_samples\n",
    "    average_accuracy = accuracy_total / total_samples\n",
    "    average_precision = precision_total / total_samples\n",
    "    average_recall = recall_total / total_samples\n",
    "    average_f1 = f1_total / total_samples\n",
    "    average_mae = mae_total / total_samples\n",
    "    average_dice = dice_total / total_samples\n",
    "\n",
    "    # 打印结果\n",
    "    print(\"平均 IoU:\", average_iou)\n",
    "    print(\"平均 Dice:\", average_dice)\n",
    "    print(\"平均准确率:\", average_accuracy)\n",
    "    print(\"平均精确率:\", average_precision)\n",
    "    print(\"平均召回率:\", average_recall)\n",
    "    print(\"平均 F1 分数:\", average_f1)\n",
    "    print(\"平均 MAE:\", average_mae)\n",
    "    print()\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(\"平均 IoU: \" + str(average_iou) + \"\\n\")\n",
    "        f.write(\"平均 Dice: \" + str(average_dice) + \"\\n\")\n",
    "        f.write(\"平均准确率: \" + str(average_accuracy) + \"\\n\")\n",
    "        f.write(\"平均精确率: \" + str(average_precision) + \"\\n\")\n",
    "        f.write(\"平均召回率: \" + str(average_recall) + \"\\n\")\n",
    "        f.write(\"平均 F1 分数: \" + str(average_f1) + \"\\n\")\n",
    "        f.write(\"平均 MAE: \" + str(average_mae) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "\n",
    "predictions_nums = [0,1,2,3,4,9,\"best\"]\n",
    "detco_nums=[\"CCAM_Apple_MOCO\"]\n",
    "detco_nums = [item for item in detco_nums for _ in range(7)]\n",
    "\n",
    "predictions_nums = [0,1,2,3,4,9,\"best\"]\n",
    "predictions_nums = predictions_nums\n",
    "detco_nums=[\"CCAM_Apple_DETCO\"]\n",
    "detco_nums = [item for item in detco_nums for _ in range(7)]\n",
    "\n",
    "predictions_nums = [0,1,2,3,4,9,\"best\"]\n",
    "predictions_nums = predictions_nums\n",
    "detco_nums=[\"CCAM_Apple_Plant\"]\n",
    "detco_nums = [item for item in detco_nums for _ in range(7)]\n",
    "\n",
    "for predictions_num, detco_num in zip(predictions_nums, detco_nums):\n",
    "    if detco_num.startswith(\"CCAM_Apple\"):\n",
    "        gt_folder = './experiments/data/万张图/Original_Resized_picture_gt'\n",
    "        pred_folder = f'./experiments/predictions_{predictions_num}/{detco_num}@scale=2,3@t=0.5@ccam_inference_crf=10'\n",
    "    elif detco_num.startswith(\"CCAM_Extra\"):\n",
    "        gt_folder = './experiments/data/万张图/Extra_Original_Resized_Leaf/Original_picture_gt'\n",
    "        pred_folder = f'./experiments/predictions_{predictions_num}/{detco_num}@scale=2,3@t=0.5@ccam_inference_crf=10'\n",
    "    tag = \"/\".join(pred_folder.split('/')[-2:])\n",
    "    print(\"tag:\", tag)\n",
    "    file_path = f\"./Eval_SOD/{tag}\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    file_path=file_path+\"/\"+\"result.txt\"\n",
    "    evaluating(pred_folder, gt_folder,file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tian_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
